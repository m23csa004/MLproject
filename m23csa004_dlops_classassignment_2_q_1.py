# -*- coding: utf-8 -*-
"""M23CSA004_DLOps_ClassAssignment_2_Q_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WZghT2nGs8cRrpWB_WYKXnPo_OmjiYIT
"""

#import necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import torchvision.transforms as transforms
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import label_binarize

# Check if CUDA is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Download USPS Dataset
usps = fetch_openml(name='usps', version=2)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(usps.data, usps.target, test_size=0.2, random_state=42)

# Convert data to numpy arrays
X_train = X_train.values.astype('float32') / 255.0
X_test = X_test.values.astype('float32') / 255.0
y_train = y_train.values.astype(np.int64)
y_test = y_test.values.astype(np.int64)

# Ensure target labels are within expected range (0 to 9)
y_train = np.clip(y_train, 0, 9)
y_test = np.clip(y_test, 0, 9)

# Convert data to PyTorch tensors and move to device
X_train_tensor = torch.tensor(X_train).reshape(-1, 1, 16, 16).to(device)
X_test_tensor = torch.tensor(X_test).reshape(-1, 1, 16, 16).to(device)
y_train_tensor = torch.tensor(y_train.astype(np.int64)).to(device)
y_test_tensor = torch.tensor(y_test.astype(np.int64)).to(device)

# Define custom dataset
class USPSDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# Create data loaders
train_dataset = USPSDataset(X_train_tensor, y_train_tensor)
test_dataset = USPSDataset(X_test_tensor, y_test_tensor)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Define MLP model
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(16*16, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)  # Flatten input
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Define a new MLP model with different architecture
class MLP2(nn.Module):
    def __init__(self):
        super(MLP2, self).__init__()
        self.fc1 = nn.Linear(16*16, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 128)
        self.fc4 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)  # Flatten input
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = self.fc4(x)
        return x

# Define another MLP model with different activation function
class MLP3(nn.Module):
    def __init__(self):
        super(MLP3, self).__init__()
        self.fc1 = nn.Linear(16*16, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)  # Flatten input
        x = torch.tanh(self.fc1(x))  # Using tanh activation function
        x = torch.tanh(self.fc2(x))  # Using tanh activation function
        x = self.fc3(x)
        return x

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(64*4*4, 256)
        self.fc2 = nn.Linear(256, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.max_pool2d(x, kernel_size=2, stride=2)
        x = torch.relu(self.conv2(x))
        x = torch.max_pool2d(x, kernel_size=2, stride=2)
        x = x.view(x.size(0), -1)  # Flatten
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

def train_model(model, train_loader, criterion, optimizer, writer, epoch):
    model.train()
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)  # Move data to device
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    writer.add_scalar('training_loss', running_loss / len(train_loader), epoch)

def test_model(model, test_loader, criterion, writer, epoch):
    model.eval()
    predictions = []
    true_labels = []
    with torch.no_grad():
        running_loss = 0.0
        for data in test_loader:
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            predictions.extend(predicted.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())
        accuracy = accuracy_score(true_labels, predictions)
        precision = precision_score(true_labels, predictions, average='macro', zero_division='warn')
        recall = recall_score(true_labels, predictions, average='macro')
        confusion = confusion_matrix(true_labels, predictions)
        writer.add_scalar('test_loss', running_loss / len(test_loader), epoch)
        writer.add_scalar('accuracy', accuracy, epoch)
        writer.add_scalar('precision', precision, epoch)
        writer.add_scalar('recall', recall, epoch)
        writer.add_figure('confusion_matrix', plot_confusion_matrix(confusion), epoch)

def plot_confusion_matrix(cm):
    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    classes = range(10)
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes)
    plt.yticks(tick_marks, classes)
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    return plt.gcf()

# Training parameters
lr = 0.001
epochs = 10

# Initialize models, criterion, optimizer
mlp_model = MLP().to(device)  # Move model to device
mlp_model2 = MLP2().to(device)  # Move model to device
mlp_model3 = MLP3().to(device)  # Move model to device
cnn_model = CNN().to(device)  # Move model to device
criterion = nn.CrossEntropyLoss()
mlp_optimizer = optim.Adam(mlp_model.parameters(), lr=lr)
mlp_optimizer2 = optim.Adam(mlp_model2.parameters(), lr=lr)
mlp_optimizer3 = optim.Adam(mlp_model3.parameters(), lr=lr)
cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=lr)

# Initialize TensorBoard writer
writer = SummaryWriter()

# Training loop for MLP model
for epoch in range(epochs):
    train_model(mlp_model, train_loader, criterion, mlp_optimizer, writer, epoch)
    test_model(mlp_model, test_loader, criterion, writer, epoch)

# Training loop for MLP2 model
for epoch in range(epochs):
    train_model(mlp_model2, train_loader, criterion, mlp_optimizer2, writer, epoch)
    test_model(mlp_model2, test_loader, criterion, writer, epoch)

# Training loop for MLP3 model
for epoch in range(epochs):
    train_model(mlp_model3, train_loader, criterion, mlp_optimizer3, writer, epoch)
    test_model(mlp_model3, test_loader, criterion, writer, epoch)

# Training loop for CNN model
for epoch in range(epochs):
    train_model(cnn_model, train_loader, criterion, cnn_optimizer, writer, epoch)
    test_model(cnn_model, test_loader, criterion, writer, epoch)

writer.close()
